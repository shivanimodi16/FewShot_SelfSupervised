# FewShot_SelfSupervised

In this research, we examine the few-shot capabilities of two well-known self-supervised learning algorithms for visual representations, SimCLR and SimSiam, and see how they stack up against their supervised counterpart. A common evaluation protocol is to train a linear classifier on top of (frozen) representations learnt by self-supervised methods. We take this protocol a step further by evaluating our supervised and self-supervised methods on a few-shot image classification task using frozen representations. In our Experiments, we find that as expected the supervised method has a higher performance than self-supervised methods SimCLR and SimSiam.

