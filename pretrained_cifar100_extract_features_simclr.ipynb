{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYF8vPYqcJ-6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets.utils import download_url\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "from glob import glob\n",
        "import re\n",
        "from itertools import compress\n",
        "import pandas as pd\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "torch.manual_seed(0)\n",
        "from torchvision.models import resnet18, resnet34"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR100\n",
        "from torchvision.models import resnet18, resnet34\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "vN7zVwjcBmS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pwX8r4afzZ7z",
        "outputId": "683b40c3-83ed-44b5-9721-38c8e6703168"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.11.1+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "torchvision.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKudmFIEOUSM",
        "outputId": "00ddfa04-2339-4058-f431-2243610b8acc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'selfSupervised_fewShot' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/samirchar/selfSupervised_fewShot.git\n",
        "from selfSupervised_fewShot.dataprep import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5EJuoxjkrzA"
      },
      "outputs": [],
      "source": [
        "target_dataset = 'CIFAR10'\n",
        "source_dataset = 'CIFAR100'\n",
        "\n",
        "img_size = 32\n",
        "train_batch_size = 32\n",
        "batch_size = 512\n",
        "num_workers = 2\n",
        "val_size = 5000\n",
        "full_train_size = 50000 #Could be automatic\n",
        "\n",
        "source_root = f'simclr_{source_dataset.lower()}'\n",
        "if not os.path.exists(source_root):\n",
        "  os.mkdir(source_root)\n",
        "lincls_path = f'{source_root}/lincls_on_{target_dataset.lower()}'\n",
        "if not os.path.exists(lincls_path):\n",
        "  os.mkdir(lincls_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqIXot_7zZ71"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class SimCLR(nn.Module):\n",
        "    def __init__(self, base_encoder, projection_dim=128):\n",
        "        super().__init__()\n",
        "        self.enc = base_encoder(pretrained=False)  # load model from torchvision.models without pretrained weights.\n",
        "        self.feature_dim = self.enc.fc.in_features\n",
        "\n",
        "        # Customize for CIFAR10. Replace conv 7x7 with conv 3x3, and remove first max pooling.\n",
        "        # See Section B.9 of SimCLR paper.\n",
        "        self.enc.conv1 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
        "        self.enc.maxpool = nn.Identity()\n",
        "        self.enc.fc = nn.Identity()  # remove final fully connected layer.\n",
        "\n",
        "        # Add MLP projection.\n",
        "        self.projection_dim = projection_dim\n",
        "        self.projector = nn.Sequential(nn.Linear(self.feature_dim, 2048),\n",
        "                                       nn.ReLU(),\n",
        "                                       nn.Linear(2048, projection_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        feature = self.enc(x)\n",
        "        projection = self.projector(feature)\n",
        "        return feature, projection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJY_JXEuzZ72"
      },
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "class CIFAR10Pair(CIFAR10):\n",
        "    \"\"\"Generate mini-batche pairs on CIFAR10 training set.\"\"\"\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = self.data[idx], self.targets[idx]\n",
        "        img = Image.fromarray(img)  # .convert('RGB')\n",
        "        imgs = [self.transform(img), self.transform(img)]\n",
        "        return torch.stack(imgs), target  # stack a positive pair\n",
        "\n",
        "\n",
        "def nt_xent(x, t=0.5):\n",
        "    x = F.normalize(x, dim=1)\n",
        "    x_scores =  (x @ x.t()).clamp(min=1e-7)  # normalized cosine similarity scores\n",
        "    x_scale = x_scores / t   # scale with temperature\n",
        "\n",
        "    # (2N-1)-way softmax without the score of i-th entry itself.\n",
        "    # Set the diagonals to be large negative values, which become zeros after softmax.\n",
        "    x_scale = x_scale - torch.eye(x_scale.size(0)).to(x_scale.device) * 1e5\n",
        "\n",
        "    # targets 2N elements.\n",
        "    targets = torch.arange(x.size()[0])\n",
        "    targets[::2] += 1  # target of 2k element is 2k+1\n",
        "    targets[1::2] -= 1  # target of 2k+1 element is 2k\n",
        "    return F.cross_entropy(x_scale, targets.long().to(x_scale.device))\n",
        "\n",
        "\n",
        "def get_lr(step, total_steps, lr_max, lr_min):\n",
        "    \"\"\"Compute learning rate according to cosine annealing schedule.\"\"\"\n",
        "    return lr_min + (lr_max - lr_min) * 0.5 * (1 + np.cos(step / total_steps * np.pi))\n",
        "\n",
        "\n",
        "# color distortion composed by color jittering and color dropping.\n",
        "# See Section A of SimCLR: https://arxiv.org/abs/2002.05709\n",
        "def get_color_distortion(s=0.5):  # 0.5 for CIFAR100 by default\n",
        "    # s is the strength of color distortion\n",
        "    color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
        "    rnd_color_jitter = transforms.RandomApply([color_jitter], p=0.8)\n",
        "    rnd_gray = transforms.RandomGrayscale(p=0.2)\n",
        "    color_distort = transforms.Compose([rnd_color_jitter, rnd_gray])\n",
        "    return color_distort\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ly407hvzZ73",
        "outputId": "a86b16e2-5c56-4bd4-9819-7522cbea623e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train_transform = transforms.Compose([transforms.RandomResizedCrop(32,scale=(0.2, 1.)),\n",
        "                                          transforms.RandomHorizontalFlip(),\n",
        "                                          get_color_distortion(s=0.5),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "                                        \n",
        "data_dir =  './data' # get absolute path of data dir\n",
        "\n",
        "trainset = CIFAR10(root=data_dir,\n",
        "                            train=True,\n",
        "                            transform=train_transform,\n",
        "                            download=True)\n",
        "\n",
        "train_loader = DataLoader(trainset,\n",
        "                              batch_size=512,\n",
        "                              shuffle=True,\n",
        "                              num_workers=0,\n",
        "                              drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdjq13YGzZ74"
      },
      "outputs": [],
      "source": [
        "test_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "\n",
        "\n",
        "test_set = CIFAR10(root=data_dir, train=False, transform=test_transform, download=False)\n",
        "\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimCLRLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "    def nt_xent(self,x,t=0.5):\n",
        "        x = F.normalize(x, dim=1)\n",
        "        x_scores =  (x @ x.t()).clamp(min=1e-7)  # normalized cosine similarity scores\n",
        "        x_scale = x_scores / t   # scale with temperature\n",
        "\n",
        "        # (2N-1)-way softmax without the score of i-th entry itself.\n",
        "        # Set the diagonals to be large negative values, which become zeros after softmax.\n",
        "        x_scale = x_scale - torch.eye(x_scale.size(0)).to(x_scale.device) * 1e5\n",
        "\n",
        "        # targets 2N elements.\n",
        "        targets = torch.arange(x.size()[0])\n",
        "        targets[::2] += 1  # target of 2k element is 2k+1\n",
        "        targets[1::2] -= 1  # target of 2k+1 element is 2k\n",
        "        return F.cross_entropy(x_scale, targets.long().to(x_scale.device))\n",
        "\n",
        "    def forward(self,x,t=0.5):\n",
        "        return nt_xent(x,t)"
      ],
      "metadata": {
        "id": "WWj_SEhlExon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinModel(nn.Module):\n",
        "    \"\"\"Linear wrapper of encoder.\"\"\"\n",
        "    def __init__(self, encoder: nn.Module, feature_dim: int, n_classes: int):\n",
        "        super().__init__()\n",
        "        self.enc = encoder\n",
        "        self.feature_dim = feature_dim\n",
        "        self.n_classes = n_classes\n",
        "        self.lin = nn.Linear(self.feature_dim, self.n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(self.enc(x))"
      ],
      "metadata": {
        "id": "EZSVNKZ6l9Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud2WdqVlBMK_",
        "outputId": "d2d85b82-d72b-46cf-c00b-5d88812e96cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimCLR(\n",
            "  (enc): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): Identity()\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Identity()\n",
            "  )\n",
            "  (projector): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=2048, out_features=128, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "backbone = 'resnet18' # or resnet34, resnet50\n",
        "projection_dim = 128 # \"[...] to project the representation to a 128-dimensional latent space\"\n",
        "#Load pretrained model on CIFAR100\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#resnet18 = resnet18_small(num_classes=100)\n",
        "base_encoder = eval('resnet18')\n",
        "model = SimCLR(base_encoder, projection_dim=128).cuda()\n",
        "model.load_state_dict(torch.load('simclr_best_resnet18.pt'))\n",
        "criterion = SimCLRLoss()\n",
        "print(model)\n",
        "#print(simclr_model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  # SimCLR training\n",
        "#     model.train()\n",
        "#     optimal_loss = 1e5\n",
        "#     for epoch in range(1, epochs + 1):\n",
        "#         loss_meter = AverageMeter(\"SimCLR_loss\")\n",
        "#         train_bar = tqdm(train_loader)\n",
        "        \n",
        "#         for x, y in train_bar:\n",
        "#             sizes = x.size()\n",
        "#             x = x.view(sizes[0] * 2, sizes[2], sizes[3], sizes[4]).cuda(non_blocking=True)\n",
        "\n",
        "#             optimizer.zero_grad()\n",
        "#             feature, rep = model(x)\n",
        "#             loss = nt_xent(rep, 0.5)\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "#             scheduler.step()\n",
        "\n",
        "#             loss_meter.update(loss.item(), x.size(0))\n",
        "#             train_bar.set_description(\"Train epoch {}, SimCLR loss: {:.4f}\".format(epoch, loss_meter.avg))\n",
        "#         train_loss.append(loss_meter.avg)    \n",
        "#         if loss_meter.avg < optimal_loss:\n",
        "#             optimal_loss = loss_meter.avg\n",
        "#             logger.info(\"==> New best results\")\n",
        "#             torch.save(model.state_dict(), 'simclr_best_{}.pt'.format(backbone))"
      ],
      "metadata": {
        "id": "Wyu_NcnIc5-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extractor2(model,layer_name,dataset,device,return_target = True):\n",
        "  return_nodes = {layer_name:'output'}\n",
        "  extractor = create_feature_extractor(model,return_nodes)\n",
        "\n",
        "  extracted_features = []\n",
        "  targets_list = []\n",
        "  with torch.no_grad():\n",
        "    for inputs, targets in dataset:\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "      sizes = inputs.size()\n",
        "      inputs = inputs.view(sizes[0] * 2, sizes[2], sizes[3], sizes[4]).cuda(non_blocking=True)\n",
        "      features = extractor(inputs)\n",
        "      print(\"features\",features['output'].shape)\n",
        "      # squeeze 1024 ,512\n",
        "      extracted_features.append(features['output'].squeeze())\n",
        "      targets_list.append(targets)\n",
        "\n",
        "  extracted_features = torch.concat(extracted_features,dim=0)\n",
        "  targets = torch.concat(targets_list,dim=0)\n",
        "  \n",
        "  if return_target:\n",
        "    return extracted_features.cpu().numpy(),targets.cpu().numpy()\n",
        "  \n",
        "  return extracted_features.cpu().numpy()\n",
        "  #return None, None"
      ],
      "metadata": {
        "id": "2CzeyioMcTiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phr0RoQsJkXX"
      },
      "outputs": [],
      "source": [
        "X_train,y_train = feature_extractor(model,'enc.avgpool',train_loader,device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test,y_test = feature_extractor(model,'enc.avgpool',test_loader,device)"
      ],
      "metadata": {
        "id": "8YCTUwrzdk1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv_ISSf9r7PH"
      },
      "outputs": [],
      "source": [
        "np.save('X_train.npy',X_train)\n",
        "\n",
        "np.save('X_test.npy',X_test)\n",
        "\n",
        "np.save('y_train.npy',y_train)\n",
        "np.save('y_test.npy',y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0Dp2WELsEsZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "pretrained_cifar100_extract_features_simclr.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}